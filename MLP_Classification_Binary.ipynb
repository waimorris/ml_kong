import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import TensorDataset, DataLoader
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

# Set random seeds for reproducibility
torch.manual_seed(42)
np.random.seed(42)

# 1. Load and prepare data
# --------------------------------------------------
train_df = pd.read_csv('/content/train.csv')
test_df = pd.read_csv('/content/test.csv')

# 2. Preprocessing
# --------------------------------------------------
def preprocess_data(df, le_geo=None, le_gen=None, le_target=None, scaler=None, is_train=True):
    df = df.copy()
    # Drop unnecessary columns
    df = df.drop(columns=['CustomerId', 'Surname', 'id'])
    
    # Separate features and target
    if is_train:
        X = df.drop(columns='Exited')  # Change to your multi-class target column
        y = df['Exited'].values
    else:
        X = df
        y = None
    
    # Initialize encoders if training
    if is_train:
        le_geo = LabelEncoder().fit(X['Geography'])
        le_gen = LabelEncoder().fit(X['Gender'])
        le_target = LabelEncoder().fit(y)
        scaler = StandardScaler().fit(X.values)
    
    # Transform features
    X['Geography'] = le_geo.transform(X['Geography'])
    X['Gender'] = le_gen.transform(X['Gender'])
    
    # Scale features
    X_scaled = scaler.transform(X.values) if is_train else scaler.transform(X)
    
    # Transform target if training
    if is_train:
        y_encoded = le_target.transform(y)
        return X_scaled, y_encoded, le_geo, le_gen, le_target, scaler
    return X_scaled

# Preprocess training data
X, y, le_geo, le_gen, le_target, scaler = preprocess_data(train_df, is_train=True)

# Split data
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# 3. Create DataLoaders
# --------------------------------------------------
def create_dataloaders(X_train, y_train, X_test, y_test, batch_size=64):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # Convert to PyTorch tensors
    X_train_t = torch.FloatTensor(X_train).to(device)
    y_train_t = torch.LongTensor(y_train).to(device)
    X_test_t = torch.FloatTensor(X_test).to(device)
    y_test_t = torch.LongTensor(y_test).to(device)
    
    # Create datasets
    train_ds = TensorDataset(X_train_t, y_train_t)
    test_ds = TensorDataset(X_test_t, y_test_t)
    
    # Create loaders
    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)
    test_loader = DataLoader(test_ds, batch_size=batch_size*2)
    
    return train_loader, test_loader

train_loader, test_loader = create_dataloaders(X_train, y_train, X_test, y_test)

# 4. Define Model
# --------------------------------------------------
class MultiClassClassifier(nn.Module):
    def __init__(self, input_size, num_classes):
        super().__init__()
        self.layers = nn.Sequential(
            nn.Linear(input_size, 128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(64, num_classes)
        )
        
    def forward(self, x):
        return self.layers(x)

# Initialize model
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = MultiClassClassifier(X_train.shape[1], len(le_target.classes_)).to(device)
optimizer = optim.Adam(model.parameters(), lr=0.001)
criterion = nn.CrossEntropyLoss()

# 5. Training Loop
# --------------------------------------------------
def train_model(model, train_loader, test_loader, epochs=30):
    best_accuracy = 0
    for epoch in range(epochs):
        # Training phase
        model.train()
        train_loss = 0
        for X_batch, y_batch in train_loader:
            optimizer.zero_grad()
            outputs = model(X_batch)
            loss = criterion(outputs, y_batch)
            loss.backward()
            optimizer.step()
            train_loss += loss.item()
        
        # Evaluation phase
        model.eval()
        test_loss = 0
        correct = 0
        total = 0
        with torch.no_grad():
            for X_batch, y_batch in test_loader:
                outputs = model(X_batch)
                loss = criterion(outputs, y_batch)
                test_loss += loss.item()
                
                _, predicted = torch.max(outputs.data, 1)
                total += y_batch.size(0)
                correct += (predicted == y_batch).sum().item()
        
        # Print metrics
        train_loss = train_loss/len(train_loader)
        test_loss = test_loss/len(test_loader)
        accuracy = 100 * correct/total
        
        print(f'Epoch {epoch+1:2}/{epochs}')
        print(f'Train Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f}')
        print(f'Test Accuracy: {accuracy:.2f}%')
        print('-'*50)
    
    return model

# Start training
trained_model = train_model(model, train_loader, test_loader, epochs=30)

# 6. Generate Predictions
# --------------------------------------------------
# Preprocess test data
X_test_sub = preprocess_data(test_df, le_geo, le_gen, le_target, scaler, is_train=False)

# Convert to tensor
X_test_sub_t = torch.FloatTensor(X_test_sub).to(device)

# Generate predictions
trained_model.eval()
with torch.no_grad():
    outputs = trained_model(X_test_sub_t)
    _, predictions = torch.max(outputs, 1)
    predictions = le_target.inverse_transform(predictions.cpu().numpy())

# Create submission file
submission = pd.DataFrame({
    'id': test_df['id'],
    'Exited': predictions  # Update column name to match your target
})

submission.to_csv('multi_class_predictions.csv', index=False)
print('Submission file saved!')

# 7. Final Evaluation Report
# --------------------------------------------------
# Get all predictions for test set
test_predictions = []
test_true = []
with torch.no_grad():
    for X_batch, y_batch in test_loader:
        outputs = trained_model(X_batch)
        _, predicted = torch.max(outputs.data, 1)
        test_predictions.extend(predicted.cpu().numpy())
        test_true.extend(y_batch.cpu().numpy())

# Decode labels
test_true_labels = le_target.inverse_transform(test_true)
test_pred_labels = le_target.inverse_transform(test_predictions)

# Generate classification report
print('\nClassification Report:')
print(classification_report(
    test_true_labels,
    test_pred_labels,
    target_names=le_target.classes_
))
